agent:
  gamma: 0.99                # Discount factor
  epsilon: 1.0               # Initial exploration probability
  epsilon_decay: 0.995       # Decay rate of epsilon
  epsilon_min: 0.1           # Minimum epsilon for exploration
  learning_rate: 0.0001      # Learning rate for the optimizer
  target_update_frequency: 10  # Update target network every N episodes

replay_buffer:
  buffer_size: 50000         # Max number of transitions to store
  batch_size: 32             # Batch size for training

environment:
  game_name: "ALE/Pong-v5"  # Name of the Atari game
  render_mode: "rgb_array"          # Render mode (e.g., "human", "rgb_array", or null)
  max_steps: 10000           # Maximum steps per episode
  episodes: 100              # Number of training episodes
  batch_size: 32             # Batch size for training
  target_update_frequency: 20  # Update target network every N episodes
